{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Basics: Maximum Likelihood Estimation\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "This is the first of a set of little blog-style post that I'm creating to get a better grasp on machine learning concepts. I'm mainly following the book \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio and Aaron Courville [1], but if any other resources are used I'll be citing them underneath this introduction. While alot of these examples are going to be ones I take from [1] I think sometimes it helps to provide some context or explanation to an equation which is what I'm going to try to do throughought this series. If you see any mistakes please feel free to email me at adibfixeshismistakes@gmail.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Refernces\n",
    "https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1 [2] (Jonny Brooks-Bartlett)\n",
    "\n",
    "https://www.probabilitycourse.com/chapter8/8_2_0_point_estimation.php [3] (Hossein Pishro-Nik)\n",
    "\n",
    "https://towardsdatascience.com/mse-and-bias-variance-decomposition-77449dd2ff55 [4] (Maksym Zavershynskyi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators\n",
    "\n",
    "Estimators are functions that can be used to provide the best possible estimate ($\\hat{\\theta}$) of some quantity of interest (${\\theta}$) where the true value $\\theta$ is some fixed quantity for the distribution. If you're thinking \"wow this is a very vague definition\", you're right, it is! If {$x^{(1)}, x^{(2)},...,x^{(m)}$} are a set of independent, identically distributed data points collected by sampling some random variable $X$. The *point estimator* is some function g such that:\n",
    "\n",
    "$$\\hat{\\theta} = g(x^{(1)}, x^{(2)}, ... x^{(m)})$$\n",
    "\n",
    "which means pretty much any function can be considered an estimator. If you are sampling some random variable ${X}$ with an unknown parametric probability density we can estimate the parameters of the model by making some educated guesses about the type of distribution the sample data best resembles. \n",
    "\n",
    "Using an example from [1], suppose we have our set of samples and they are distributed according to some gaussian distribution with unknown parameters $\\mu$ and $\\sigma^2$. We have:\n",
    "\n",
    "$$ P(x^{(i)}; \\mu; \\sigma^2) = N(x^{(i)}; \\mu; \\sigma^2) $$\n",
    "\n",
    "$$ P(x^{(i)}; \\mu; \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp^{-\\frac{(x^{(i)} - \\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "We dont know $\\mu$ or $\\sigma^2$, just that the sampled data may be modelled by a gaussian distribution, but we can estimate $\\hat{\\mu}$ by just taking the average value of all of the sampled points.\n",
    "\n",
    "$$\\hat{\\mu} = \\frac{1}{m}\\sum^{m}_{i=1}x^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Estimators\n",
    "\n",
    "Notice that while this example has a pretty reasonable estimator for $\\hat{\\mu}$, the definition of an estimator makes no guarantees that the estimator will accurately predict the value that its trying to estimate. So we need some measure of how well an estimator will perform, or more importantly how closely it will come to the true value of $\\theta$. The *bias* and *variance* of an estimator are measures of its offset from the true value of $\\theta$ and how much it will vary as we apply the estimator to multiple independently sampled data sets. They are defined as:\n",
    "\n",
    "$$ Bias(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta $$\n",
    "\n",
    "$$ Variance = Var(\\hat{\\theta})$$\n",
    "\n",
    "Continuing the example from before, the bias for our estimator of $\\hat{\\mu}$ can be calculated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Bias(\\hat{\\mu}) &= E[\\hat{\\mu}] - \\mu \\\\\n",
    "                &= E[\\frac{1}{m}\\sum^{m}_{i=1}x^{(i)}] - \\mu \\\\\n",
    "                &= \\frac{1}{m}\\sum^{m}_{i=1}E[x^{(i)}] - \\mu \\\\\n",
    "                &= \\frac{1}{m}\\sum^{m}_{i=1}\\mu - \\mu \\\\\n",
    "                &= \\mu - \\mu \\\\\n",
    "                &= 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This shows that using the sample mean as an estimate for the gaussian mean parameter results in an unbiased estimator.\n",
    "\n",
    "Similarly we can try to calculate the variance of the estimator.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(\\hat{\\mu}) &= Var(\\frac{1}{m}\\sum^{m}_{i=1}x^{(i)}) \\\\\n",
    "               &= \\frac{1}{m}Var(\\sum^{m}_{i=1}x^{(i)}) \\\\\n",
    "               &= \\frac{1}{m}\\sum^{m}_{i=1}Var(x^{(i)}) \\\\\n",
    "               &= \\sigma^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "While these metrics are useful ultimately what we want to do when choosing between estimators is to pick the one with the lowest amount of error between $\\hat{\\theta}$ and $\\theta$. Mean squared error does exactly this, and is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "MSE(\\hat{\\theta}) &= E[(\\hat{\\theta} - \\theta)^2] \\\\\n",
    "                  &= E[(\\hat{\\theta}^2 - 2 \\hat{\\theta}\\theta + \\theta^2] \\\\\n",
    "                  &= E[(\\hat{\\theta}^2] - 2E[\\hat{\\theta}\\theta] + E[\\theta^2]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "I decomposed the equation a little bit to show you the dependence of the MSE on the bias and variance of an estimator. To complete this derivation we need to work out two other derivations.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Bias(\\hat{\\theta})^2 &= (E[\\hat{\\theta}] - \\theta)^2 \\\\\n",
    "                     &= (E[\\hat{\\theta}])^2 - 2E[\\hat{\\theta}\\theta] + E[\\theta^2] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We assume that the real value $\\theta$ isn't a random variable, so its expectation is equal to its value. This leaves us with:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Bias(\\hat{\\theta})^2 &= (E[\\hat{\\theta}])^2 - 2\\theta E[\\hat{\\theta}] + \\theta^2 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The second derivation we need is a decomposition of the variance of an estimator.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(\\hat{\\theta}) &= E[(\\hat{\\theta} - E[\\hat{\\theta}])^2] \\\\\n",
    "                  &= E[(\\hat{\\theta}^2 - 2\\hat{\\theta}E[\\hat{\\theta}] + (E[\\hat{\\theta}])^2] \\\\\n",
    "                  &= E[(\\hat{\\theta}^2] - 2E[\\hat{\\theta}E[\\hat{\\theta}]] + E[(E[\\hat{\\theta}])^2] \\\\\n",
    "                  &= E[(\\hat{\\theta}^2] - 2E[\\hat{\\theta}]^2 + E[\\hat{\\theta}]^2 \\\\\n",
    "                  &= E[(\\hat{\\theta}^2] - E[\\hat{\\theta}]^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "A potentially non-obvious trick that is used in the derivation above is that $E[E[x]]$ is actually taking the expected value of a scalar non-random variable, so its equal to $E[x]$. This is how we are able to convert $2E[\\hat{\\theta}E[\\hat{\\theta}]] = 2E[\\hat{\\theta}]^2$ and likewise, $E[(E[\\hat{\\theta}])^2] = E[\\hat{\\theta}]^2$.\n",
    "\n",
    "Now finally, if we put these two derivations together:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(\\hat{\\theta}) + Bias(\\hat{\\theta})^2 &= E[(\\hat{\\theta}^2] - E[\\hat{\\theta}]^2 + (E[\\hat{\\theta}])^2 - 2E[\\hat{\\theta}\\theta] + E[\\theta^2] \\\\\n",
    "                                        &= E[(\\hat{\\theta}^2] + 2E[\\hat{\\theta}\\theta] + E[\\theta^2] \\\\\n",
    "                                        &= MSE(\\hat{\\theta})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This might seem like a long walk for a small drink of water but this derivation of the bias-variance decomposition of the MSE shows that when comparing the viability of two seperate estimators we dont really care about the variance or bias independently, but rather the balance between then that achieves the lowest MSE (obviously ideally we want both of them to be low!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators in Machine Learning\n",
    "So far I've only been talking about point estimators, but as mentionned earlier an estimator can also be a function. In this case instead of trying to estimate the value of some quantity $\\theta$ we are trying to estimate the relationship between two quantities. In this scenario we want to generate a function estimator on a training set of I.I.D data, and then use this estimator on a completely different set (the test data) to try and accurately predict. Suppose our desired output quantity is $y$ and we have a set of I.I.D data samples {$x^{(1)}, x^{(2)}..., x^{(m)}$} in some training dataset S. We want to find an estimate $\\hat{f}_S$ of some function f such that:\n",
    "\n",
    "$$\n",
    "y = f(x) + \\epsilon\n",
    "$$\n",
    "\n",
    "Where $\\epsilon$ represents all of the noise components of y that cannot be estimated from just $x$ alone with some probability distribution that is different from $S$. In this scenario we want to calculate MSE as:\n",
    "$$\n",
    "MSE = E[(y - \\hat{f}_S(x))^2]\n",
    "$$\n",
    "\n",
    "We can decompose this equation into some key components but we need to utilize some key identities of the variance and expected value of two random variables. The derivation for these identities are going to be omitted, since they're widely available online. Note both a and b in the identities below are random variables. These identities are identical to those presented in [4].\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(a) &= E[a^2] - E^2[a]\\\\\n",
    "E[ab] &= E[a]E[b] + Cov(a,b) \\\\\n",
    "Var(a + b) &= Var(a) + Var(b) + 2Cov(a,b) \\\\\n",
    "Var(a - b) &= Var(a) + var(b) - 2Cov(a,b) \\\\\n",
    "Cov(a, b) &= 0\\ when\\ a\\ and\\ b\\ are\\ independent\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now we can break down $MSE[\\hat{f(x)}]$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "MSE[\\hat{f(x)}] &= E[(y - \\hat{f(x)})^2] \\\\\n",
    "&= E[y^2] - 2E[y\\hat{f(x)}] + E[\\hat{f(x)}^2] \\\\\n",
    "&= Var(y) + E[y]^2 + Var(\\hat{f(x)}) + E[\\hat{f(x)}]^2 -2E[y\\hat{f(x)}] \\\\\n",
    "&= Var(y) + E[y]^2 + Var(\\hat{f(x)}) + E[\\hat{f(x)}]^2 -2E[(f(x) + \\epsilon)\\hat{f(x)}] \\\\\n",
    "&= Var(y) + E[y]^2 + Var(\\hat{f(x)}) + E[\\hat{f(x)}]^2 -2E[(f(x))(\\hat{f(x))}] -2E[\\epsilon\\hat{f(x)}]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can now take advantage of the fact that $y = f(x) + \\epsilon$. This has already been used to simplify the $-2E[y\\hat{f(x)}]$ term, but now we can apply it to get a variance and bias term in terms of $f(x)$ and $\\hat{f(x)$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&= Var(f(x) + \\epsilon) + E[f(x) + \\epsilon]^2 + Var(\\hat{f(x)}) + E[\\hat{f(x)}]^2 -2E[(f(x))]E[(\\hat{f(x))}] - 2Cov(f(x), \\hat{f(x)}) -2E[\\epsilon\\hat{f(x)}] \\\\\n",
    "&= Var(f(x)) + Var(\\epsilon) - 2Cov(f(x), \\epsilon) + E[f(x)]^2 + 2E[\\epsilon]E[f(x)] + 2E[\\epsilon]^2 + Var(\\hat{f(x)}) + E[\\hat{f(x)}]^2 -2E[(f(x))]E[(\\hat{f(x))}] + Cov(f(x), \\hat{f(x)}) -2E[\\epsilon\\hat{f(x)}] \\\\\n",
    "&= Var(f(x) - \\hat{f(x)}) + E[f(x)]^2 - 2E[f(x)]E[\\hat{f(x)}] + E[\\hat{f(x)}]^2 + Var(\\epsilon) - 2Cov(f(x), \\epsilon) + 2E[\\epsilon]E[f(x)] + 2E[\\epsilon]^2 - 2E[\\epsilon\\hat{f(x)}]\\\\\n",
    "&= Var(f(x) - \\hat{f(x)}) + (E[f(x)] - E[\\hat{f(x)}])^2 + Var(\\epsilon) - 2Cov(f(x), \\epsilon) + 2E[\\epsilon]E[f(x)] + 2E[\\epsilon]^2 - 2E[\\epsilon\\hat{f(x)}]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can simplify this a little further by assuming that the noise term $\\epsilon$ is independent of our data set $S$, and that it has some constant mean $c$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&= Var(f(x) - \\hat{f(x)}) + (E[f(x)] - E[\\hat{f(x)}])^2 + Var(\\epsilon) - 2cE[f(x)] + 2c^2 - 2cE[\\hat{f(x)}]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This can be simplified further still if we assume our noise model has mean $c=0$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&= Var(f(x) - \\hat{f(x)}) + (E[f(x)] - E[\\hat{f(x)}])^2 + Var(\\epsilon)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We're left with an equation that is very similar to the bias-variance decomposition of the MSE for point estimators. The variance term is $Var(f(x) - \\hat{f(x)})$, measuring the amount of jitter we can expect the difference between the true model f(x) and $\\hat{f(x)}$ to be as we vary $S$. The bias term is $(E[f(x)] - E[\\hat{f(x)}])^2$, which is a measure of how well the estimator model will approximate the real model. Finally we have an additional term $Var(\\epsilon)$ which is a measure of how much the noise term will impact the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood Estimation\n",
    "So far most of the analysis in this post has been about evaluating estimators. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
